{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d402f55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from melo.text import english, malay\n",
    "from melo.text.japanese import distribute_phone\n",
    "from melo.text.english_bert import get_bert_feature\n",
    "from melo.text.malay_bert import get_bert_feature as get_malay_bert_feature\n",
    "from melo.text.japanese import distribute_phone\n",
    "from melo.text.cleaner import clean_text_bert\n",
    "from melo.text.symbols import symbols\n",
    "len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7b37b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['_', 'hh', 'ah', 'l', 'ow', 'm', 'ay', 'n', 'ey', 'm', '.', '_'],\n",
       " [0, 0, 1, 0, 2, 0, 2, 0, 2, 0, 0, 0],\n",
       " [1, 4, 2, 3, 1, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'hello my name.'\n",
    "text = english.text_normalize(text)\n",
    "phones, tones, word2ph = english.g2p(text)\n",
    "phones, tones, word2ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1cfb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = get_bert_feature(text, word2ph)\n",
    "bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5e89f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`openai-whisper` is not available, native whisper processor is not available, will use huggingface processor instead.\n",
      "/home/husein/.local/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/.local/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/.local/lib/python3.10/site-packages/malaya/normalizer/rules.py:204: FutureWarning: Possible nested set at position 42\n",
      "  k.lower(): re.compile(_expressions[k]) for k, v in _expressions.items()\n",
      "/home/husein/.local/lib/python3.10/site-packages/malaya/normalizer/rules.py:204: FutureWarning: Possible nested set at position 3\n",
      "  k.lower(): re.compile(_expressions[k]) for k, v in _expressions.items()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['_',\n",
       "  'h',\n",
       "  'e',\n",
       "  'l',\n",
       "  'l',\n",
       "  'o',\n",
       "  ' ',\n",
       "  'n',\n",
       "  'a',\n",
       "  'm',\n",
       "  'a',\n",
       "  ' ',\n",
       "  's',\n",
       "  'a',\n",
       "  'y',\n",
       "  'a',\n",
       "  ' ',\n",
       "  'H',\n",
       "  'u',\n",
       "  's',\n",
       "  'e',\n",
       "  'i',\n",
       "  'n',\n",
       "  ' ',\n",
       "  '.',\n",
       "  ' ',\n",
       "  '_'],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [1, 6, 5, 5, 7, 2, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'hello nama saya Husein.'\n",
    "text = malay.text_normalize(text)\n",
    "phones, tones, word2ph = malay.g2p(text)\n",
    "phones, tones, word2ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6a9fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phones) == sum(word2ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bbe40ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 27])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = get_malay_bert_feature(text, word2ph)\n",
    "bert.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
